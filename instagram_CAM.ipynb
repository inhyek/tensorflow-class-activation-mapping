{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_activation_map import *\n",
    "from lenet_slim import le_net\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256 \n",
    "dataset_percentage = 1.0 # 1.0 takes 100k rows. 0.1 takes 10k rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1340 images.\n",
      "read 1000 images.\n",
      "(1340,)\n",
      "Finished reading the dataset...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    [images_train, labels_train], [images_test, labels_test] = read_dataset(dataset_percentage)\n",
    "    print('Finished reading the dataset...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "!!!!! error for 3\n",
      "!!!!! error for 4\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "!!!!! error for 47\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "!!!!! error for 50\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "!!!!! error for 54\n",
      "!!!!! error for 55\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "!!!!! error for 81\n",
      "(100, 100, 3)\n",
      "!!!!! error for 83\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "!!!!! error for 90\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "(100, 100, 3)\n",
      "!!!!! error for 98\n",
      "(100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    try:\n",
    "        print(images[i].shape)\n",
    "        \n",
    "    except:\n",
    "        print('!!!!! error for', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "with open('data/instagram_labels.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            [_, label] = l.strip().split('\\t')\n",
    "            labels.append(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    labels = np.array(labels)\n",
    "    images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "images = []\n",
    "n = len(glob('data/resize/*.png'))\n",
    "assert n == len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1340 images.\n"
     ]
    }
   ],
   "source": [
    "max_images = int(percentage * n)\n",
    "labels = labels[:max_images]\n",
    "print('found {} images.'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1000 images.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, n + 1):\n",
    "    f = 'data/resize/img_{}.png'.format(i)\n",
    "    images.append(load_image(f))\n",
    "    if i % 1000 == 0:\n",
    "        print('read {} images.'.format(i))\n",
    "    if len(images) == max_images:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-977a52b46478>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "images[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, ..., 30, 30, 30])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
       "       30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-fc8979e3700b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mim_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "im_width = images_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9ae5996d0719>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mim_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "im_height = images_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert im_height == im_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, im_width, im_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, top_conv = le_net(images=x, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_activation_map = get_class_map(0, top_conv, im_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.int64, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\mnist-cluttered-99900\n",
      "checkpoint restored = checkpoints\\mnist-cluttered-99900\n"
     ]
    }
   ],
   "source": [
    "step_start = restore(sess, saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished initializing the model...\n"
     ]
    }
   ],
   "source": [
    "print('Finished initializing the model...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99901"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99901\n",
      "99902\n",
      "99903\n",
      "99904\n",
      "99905\n",
      "99906\n",
      "99907\n",
      "99908\n",
      "99909\n",
      "99910\n",
      "steps = 25576960 mean accuracy = 0.9975142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\inhyek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\skimage\\util\\dtype.py:141: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99911\n",
      "99912\n",
      "99913\n",
      "99914\n",
      "99915\n",
      "99916\n",
      "99917\n",
      "99918\n",
      "99919\n",
      "99920\n",
      "steps = 25579520 mean accuracy = 0.9953835\n",
      "99921\n",
      "99922\n",
      "99923\n",
      "99924\n",
      "99925\n",
      "99926\n",
      "99927\n",
      "99928\n",
      "99929\n",
      "99930\n",
      "steps = 25582080 mean accuracy = 0.9964489\n",
      "99931\n",
      "99932\n",
      "99933\n",
      "99934\n",
      "99935\n",
      "99936\n",
      "99937\n",
      "99938\n",
      "99939\n",
      "99940\n",
      "steps = 25584640 mean accuracy = 0.99715906\n",
      "99941\n",
      "99942\n",
      "99943\n",
      "99944\n",
      "99945\n",
      "99946\n",
      "99947\n",
      "99948\n",
      "99949\n",
      "99950\n",
      "steps = 25587200 mean accuracy = 0.9946733\n",
      "99951\n",
      "99952\n",
      "99953\n",
      "99954\n",
      "99955\n",
      "99956\n",
      "99957\n",
      "99958\n",
      "99959\n",
      "99960\n",
      "steps = 25589760 mean accuracy = 0.99715906\n",
      "99961\n",
      "99962\n",
      "99963\n",
      "99964\n",
      "99965\n",
      "99966\n",
      "99967\n",
      "99968\n",
      "99969\n",
      "99970\n",
      "steps = 25592320 mean accuracy = 0.996804\n",
      "99971\n",
      "99972\n",
      "99973\n",
      "99974\n",
      "99975\n",
      "99976\n",
      "99977\n",
      "99978\n",
      "99979\n",
      "99980\n",
      "steps = 25594880 mean accuracy = 0.99396306\n",
      "99981\n",
      "99982\n",
      "99983\n",
      "99984\n",
      "99985\n",
      "99986\n",
      "99987\n",
      "99988\n",
      "99989\n",
      "99990\n",
      "steps = 25597440 mean accuracy = 0.99715906\n",
      "99991\n",
      "99992\n",
      "99993\n",
      "99994\n",
      "99995\n",
      "99996\n",
      "99997\n",
      "99998\n",
      "99999\n"
     ]
    }
   ],
   "source": [
    " for i in range(step_start, 100000):\n",
    "        print(i)\n",
    "        batch_xs, batch_ys, _ = next_batch(images_train, labels_train, i, batch_size)\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        if i % 10 == 0:\n",
    "            save(sess, saver, i)\n",
    "            accuracy_list = []\n",
    "            j = 0\n",
    "            while True:\n",
    "                batch_xt, batch_yt, reset = next_batch(images_test, labels_test, j, batch_size, debug=False)\n",
    "                if reset:\n",
    "                    break\n",
    "                accuracy_list.append(sess.run(accuracy, feed_dict={x: batch_xt, y_: batch_yt}))\n",
    "                j += 1\n",
    "            print('steps =', i * batch_size, 'mean accuracy =', np.mean(accuracy_list))\n",
    "\n",
    "            inspect_class_activation_map(sess, class_activation_map, top_conv, images_test,\n",
    "                                         labels_test, i, 50, x, y_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
