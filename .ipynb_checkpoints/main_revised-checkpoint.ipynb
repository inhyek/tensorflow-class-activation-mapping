{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_activation_map import *\n",
    "from lenet_slim import le_net\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256 \n",
    "dataset_percentage = 0.1 # 1.0 takes 100k rows. 0.1 takes 10k rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 100000 images.\n",
      "read 1000 images.\n",
      "read 2000 images.\n",
      "read 3000 images.\n",
      "read 4000 images.\n",
      "read 5000 images.\n",
      "read 6000 images.\n",
      "read 7000 images.\n",
      "read 8000 images.\n",
      "read 9000 images.\n",
      "read 10000 images.\n",
      "(10000, 100, 100, 3)\n",
      "Finished reading the dataset...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    [images_train, labels_train], [images_test, labels_test] = read_dataset(dataset_percentage)\n",
    "    print('Finished reading the dataset...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 100, 100, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = images_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_height = images_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert im_height == im_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, im_width, im_width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, top_conv = le_net(images=x, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_activation_map = get_class_map(0, top_conv, im_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.int64, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\inhyek\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(tf.global_variables(), max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\mnist-cluttered-99900\n",
      "checkpoint restored = checkpoints\\mnist-cluttered-99900\n"
     ]
    }
   ],
   "source": [
    "step_start = restore(sess, saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished initializing the model...\n"
     ]
    }
   ],
   "source": [
    "print('Finished initializing the model...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99901"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99901\n",
      "99902\n",
      "99903\n",
      "99904\n",
      "99905\n",
      "99906\n",
      "99907\n",
      "99908\n",
      "99909\n",
      "99910\n",
      "99911\n",
      "99912\n",
      "99913\n",
      "99914\n",
      "99915\n",
      "99916\n",
      "99917\n",
      "99918\n",
      "99919\n",
      "99920\n",
      "99921\n",
      "99922\n",
      "99923\n",
      "99924\n",
      "99925\n",
      "99926\n",
      "99927\n",
      "99928\n",
      "99929\n",
      "99930\n",
      "99931\n",
      "99932\n",
      "99933\n",
      "99934\n",
      "99935\n",
      "99936\n",
      "99937\n",
      "99938\n",
      "99939\n",
      "99940\n",
      "99941\n",
      "99942\n",
      "99943\n",
      "99944\n",
      "99945\n",
      "99946\n",
      "99947\n",
      "99948\n",
      "99949\n",
      "99950\n",
      "99951\n",
      "99952\n",
      "99953\n",
      "99954\n",
      "99955\n",
      "99956\n",
      "99957\n",
      "99958\n",
      "99959\n",
      "99960\n",
      "99961\n",
      "99962\n",
      "99963\n",
      "99964\n",
      "99965\n",
      "99966\n",
      "99967\n",
      "99968\n",
      "99969\n",
      "99970\n",
      "99971\n",
      "99972\n",
      "99973\n",
      "99974\n",
      "99975\n",
      "99976\n",
      "99977\n",
      "99978\n",
      "99979\n",
      "99980\n",
      "99981\n",
      "99982\n",
      "99983\n",
      "99984\n",
      "99985\n",
      "99986\n",
      "99987\n",
      "99988\n",
      "99989\n",
      "99990\n",
      "99991\n",
      "99992\n",
      "99993\n",
      "99994\n",
      "99995\n",
      "99996\n",
      "99997\n",
      "99998\n",
      "99999\n"
     ]
    }
   ],
   "source": [
    " for i in range(step_start, 100000):\n",
    "        print(i)\n",
    "        batch_xs, batch_ys, _ = next_batch(images_train, labels_train, i, batch_size)\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        if i % 100 == 0:\n",
    "            save(sess, saver, i)\n",
    "            accuracy_list = []\n",
    "            j = 0\n",
    "            while True:\n",
    "                batch_xt, batch_yt, reset = next_batch(images_test, labels_test, j, batch_size, debug=False)\n",
    "                if reset:\n",
    "                    break\n",
    "                accuracy_list.append(sess.run(accuracy, feed_dict={x: batch_xt, y_: batch_yt}))\n",
    "                j += 1\n",
    "            print('steps =', i * batch_size, 'mean accuracy =', np.mean(accuracy_list))\n",
    "\n",
    "            inspect_class_activation_map(sess, class_activation_map, top_conv, images_test,\n",
    "                                         labels_test, i, 50, x, y_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
